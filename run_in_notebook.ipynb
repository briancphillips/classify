{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from run_experiments import ExperimentManager\n",
    "from utils.logging import setup_logging, get_logger\n",
    "from utils.error_logging import get_error_logger\n",
    "\n",
    "# Initialize logging\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)\n",
    "error_logger = get_error_logger()\n",
    "\n",
    "# Create experiment manager\n",
    "config_path = 'experiments/config.yaml'\n",
    "manager = ExperimentManager(config_path)\n",
    "\n",
    "# Override configs for debugging\n",
    "debug_config = {\n",
    "    'dataset_overrides': {\n",
    "        'cifar100': {\n",
    "            'epochs': 200,  # Run fewer epochs for debugging\n",
    "            'batch_size': 128  # Smaller batch size\n",
    "        },\n",
    "        'gtsrb': {\n",
    "            'epochs': 10,  # Run fewer epochs for debugging\n",
    "            'batch_size': 128  # Smaller batch size\n",
    "        },\n",
    "        'imagenette': {\n",
    "            'epochs': 10,  # Run fewer epochs for debugging\n",
    "            'batch_size': 64  # Smaller batch size\n",
    "        }\n",
    "    },\n",
    "    'execution': {\n",
    "        'max_workers': 1  # Run sequentially\n",
    "    },\n",
    "    'experiment_groups': {\n",
    "        # Run only one experiment for debugging\n",
    "        'basic_comparison': {\n",
    "            'description': 'Basic comparison of attacks across different datasets',  # Added description\n",
    "            'experiments': [{\n",
    "                'name': 'cifar100_debug',\n",
    "                'dataset': 'cifar100',\n",
    "                'attacks': ['ga','label_flip']  # Just one attack\n",
    "            },{\n",
    "                'name': 'gtsrb_debug',\n",
    "                'dataset': 'gtsrb',\n",
    "                'attacks': ['pgd','ga','label_flip']  # Just one attack\n",
    "            },{\n",
    "                'name': 'imagnette_debug',\n",
    "                'dataset': 'imagenette',\n",
    "                'attacks': ['pgd','ga','label_flip']  # Just one attack\n",
    "            }]\n",
    "        \n",
    "        }   \n",
    "    }\n",
    "}\n",
    "\n",
    "# Use the context manager for temporary overrides\n",
    "with manager.override_config(**debug_config):\n",
    "    # Log device information\n",
    "    device_info = manager._get_device_info()\n",
    "    logger.info(f\"Running experiments on: {device_info}\")\n",
    "    logger.info(f\"Total experiments to run: {manager.total_experiments}\")\n",
    "    \n",
    "    # Run experiments with temporary config\n",
    "    manager.run_experiments()\n",
    "\n",
    "# Config automatically resets after the with block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "import logging\n",
    "import os\n",
    "from run_experiments import ExperimentManager\n",
    "from utils.logging import setup_logging, get_logger\n",
    "from utils.error_logging import get_error_logger\n",
    "from config.defaults import (\n",
    "    TRAINING_DEFAULTS, \n",
    "    DATASET_DEFAULTS, \n",
    "    POISON_DEFAULTS, \n",
    "    OUTPUT_DEFAULTS, \n",
    "    EXECUTION_DEFAULTS,\n",
    "    get_dataset_config,\n",
    "    get_poison_config\n",
    ")\n",
    "\n",
    "# Initialize logging\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)\n",
    "error_logger = get_error_logger()\n",
    "\n",
    "# Create experiment manager with base config\n",
    "config_path = 'experiments/config.yaml'\n",
    "manager = ExperimentManager(config_path)\n",
    "\n",
    "# Function to check for checkpoints\n",
    "def find_checkpoint(model_type='wideresnet'):\n",
    "    checkpoint_dir = Path('~/Notebooks/classify/checkpoints') / model_type\n",
    "    checkpoint_dir = checkpoint_dir.expanduser()\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        logger.warning(f\"Checkpoint directory {checkpoint_dir} does not exist\")\n",
    "        return None\n",
    "        \n",
    "    # First try to find best checkpoint\n",
    "    best_checkpoint = checkpoint_dir / 'wideresnet_best.pt'\n",
    "    if best_checkpoint.exists():\n",
    "        logger.info(f\"Found best checkpoint: {best_checkpoint}\")\n",
    "        return best_checkpoint\n",
    "        \n",
    "    # Otherwise get latest checkpoint\n",
    "    latest_checkpoint = checkpoint_dir / 'wideresnet_latest.pt'\n",
    "    if latest_checkpoint.exists():\n",
    "        logger.info(f\"Found latest checkpoint: {latest_checkpoint}\")\n",
    "        return latest_checkpoint\n",
    "        \n",
    "    logger.warning(f\"No checkpoints found in {checkpoint_dir}\")\n",
    "    return None\n",
    "\n",
    "# Get checkpoint path\n",
    "checkpoint_path = find_checkpoint()\n",
    "if checkpoint_path:\n",
    "    logger.info(f\"Using checkpoint: {checkpoint_path}\")\n",
    "else:\n",
    "    logger.warning(\"No checkpoint found, will train from scratch\")\n",
    "\n",
    "# Debug configuration with checkpoint handling\n",
    "debug_config = {\n",
    "    'dataset_overrides': {\n",
    "        'cifar100': {\n",
    "            **get_dataset_config('cifar100'),\n",
    "            'epochs': 200,\n",
    "            'batch_size': 128,\n",
    "            'checkpoint_path': str(checkpoint_path) if checkpoint_path else None,\n",
    "            'model': 'wideresnet',  # Specify model type\n",
    "            'num_workers': 4 if not torch.backends.mps.is_available() else 0,\n",
    "            'pin_memory': True\n",
    "        },\n",
    "        'gtsrb': {\n",
    "            **get_dataset_config('gtsrb'),\n",
    "            'epochs': 10,\n",
    "            'batch_size': 128,\n",
    "            'checkpoint_path': str(checkpoint_path) if checkpoint_path else None,\n",
    "            'model': 'wideresnet',  # Specify model type\n",
    "            'num_workers': 4 if not torch.backends.mps.is_available() else 0,\n",
    "            'pin_memory': True\n",
    "        },\n",
    "        'imagenette': {\n",
    "            **get_dataset_config('imagenette'),\n",
    "            'epochs': 10,\n",
    "            'batch_size': 64,\n",
    "            'checkpoint_path': str(checkpoint_path) if checkpoint_path else None,\n",
    "            'model': 'wideresnet',  # Specify model type\n",
    "            'num_workers': 4 if not torch.backends.mps.is_available() else 0,\n",
    "            'pin_memory': True\n",
    "        }\n",
    "    },\n",
    "    'execution': {\n",
    "        **EXECUTION_DEFAULTS,\n",
    "        'max_workers': 1,\n",
    "        'gpu_ids': [0] if torch.cuda.is_available() else []\n",
    "    },\n",
    "    'output': {\n",
    "        **OUTPUT_DEFAULTS,\n",
    "        'base_dir': 'results',\n",
    "        'save_model': True,\n",
    "        'save_frequency': 10,\n",
    "        'consolidated_file': 'debug_results.csv',\n",
    "        'save_individual_results': True\n",
    "    },\n",
    "    'experiment_groups': {\n",
    "        'basic_comparison': {\n",
    "            'description': 'Basic comparison of attacks across different datasets',\n",
    "            'experiments': [{\n",
    "                'name': 'cifar100_debug',\n",
    "                'dataset': 'cifar100',\n",
    "                'model': 'wideresnet',  # Specify model type\n",
    "                'attacks': ['ga', 'label_flip'],\n",
    "                'poison_config': {\n",
    "                    **get_poison_config('ga'),\n",
    "                    'poison_ratio': 0.1,\n",
    "                    'batch_size': 32,\n",
    "                    'ga_steps': 50,\n",
    "                    'ga_iterations': 100,\n",
    "                    'ga_lr': 0.1\n",
    "                }\n",
    "            },{\n",
    "                'name': 'gtsrb_debug',\n",
    "                'dataset': 'gtsrb',\n",
    "                'model': 'wideresnet',  # Specify model type\n",
    "                'attacks': ['pgd', 'ga', 'label_flip'],\n",
    "                'poison_config': {\n",
    "                    **get_poison_config('pgd'),\n",
    "                    'poison_ratio': 0.1,\n",
    "                    'batch_size': 32,\n",
    "                    'pgd_eps': 0.3,\n",
    "                    'pgd_alpha': 0.01,\n",
    "                    'pgd_steps': 40\n",
    "                }\n",
    "            },{\n",
    "                'name': 'imagenette_debug',\n",
    "                'dataset': 'imagenette',\n",
    "                'model': 'wideresnet',  # Specify model type\n",
    "                'attacks': ['pgd', 'ga', 'label_flip'],\n",
    "                'poison_config': {\n",
    "                    **get_poison_config('pgd'),\n",
    "                    'poison_ratio': 0.1,\n",
    "                    'batch_size': 32,\n",
    "                    'pgd_eps': 0.3,\n",
    "                    'pgd_alpha': 0.01,\n",
    "                    'pgd_steps': 40\n",
    "                }\n",
    "            }]\n",
    "        }   \n",
    "    }\n",
    "}\n",
    "\n",
    "# Create a deep copy of the original config\n",
    "original_config = deepcopy(manager.config)\n",
    "\n",
    "try:\n",
    "    # Properly merge configurations\n",
    "    merged_config = deepcopy(original_config)\n",
    "    merged_config = deep_update(merged_config, debug_config)\n",
    "    \n",
    "    # Update manager's config\n",
    "    manager.config = merged_config\n",
    "    \n",
    "    # Log device information and CUDA details\n",
    "    if torch.cuda.is_available():\n",
    "        device_info = f\"CUDA (GPU: {torch.cuda.get_device_name(0)})\"\n",
    "        logger.info(f\"CUDA Version: {torch.version.cuda}\")\n",
    "        logger.info(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device_info = \"MPS (Apple Silicon)\"\n",
    "    else:\n",
    "        device_info = \"CPU\"\n",
    "    \n",
    "    logger.info(f\"Running experiments on: {device_info}\")\n",
    "    logger.info(f\"Total experiments to run: {manager.total_experiments}\")\n",
    "    \n",
    "    # Run experiments with merged config\n",
    "    manager.run_experiments()\n",
    "    \n",
    "finally:\n",
    "    # Always restore original config\n",
    "    manager.config = original_config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
