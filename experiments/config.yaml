# Default configuration that applies to all experiments unless overridden
defaults:
  batch_size: 128
  num_workers: 4
  pin_memory: true
  use_amp: true
  use_swa: true
  use_mixup: true
  label_smoothing: 0.1
  
  # Optimizer settings
  optimizer: SGD
  learning_rate: 0.1
  momentum: 0.9
  weight_decay: 5e-4
  
  # Learning rate schedule
  lr_schedule: [60, 120, 160]
  lr_factor: 0.2
  
  # SWA settings
  swa_start: 160
  swa_lr: 0.05
  
  # Early stopping
  patience: 20
  min_delta: 0.001
  
  # Data augmentation
  random_crop: true
  random_horizontal_flip: true
  normalize: true
  cutout: true
  cutout_length: 16

# Dataset-specific defaults
dataset_defaults:
  cifar100:
    epochs: 200
    model: wrn-28-10
    num_classes: 100
    
  gtsrb:
    epochs: 10
    learning_rate: 0.001
    
  imagenette:
    epochs: 10
    learning_rate: 0.001

# Experiment groups
experiment_groups:
  basic_comparison:
    description: "Basic comparison of all attacks across datasets"
    experiments:
      - name: cifar100_all_attacks
        dataset: cifar100
        attacks: [pgd, ga, label_flip]
      
      - name: gtsrb_all_attacks
        dataset: gtsrb
        subset_size: 10
        attacks: [pgd, ga, label_flip]
      
      - name: imagenette_all_attacks
        dataset: imagenette
        subset_size: 10
        attacks: [pgd, ga, label_flip]

  label_flip_variants:
    description: "Different variants of label flip attacks"
    experiments:
      - name: cifar100_random_to_target
        dataset: cifar100
        attack: label_flip
        target_class: 0
      
      - name: cifar100_source_to_target
        dataset: cifar100
        attack: label_flip
        source_class: 1
        target_class: 0

  quick_test:
    description: "Quick test of result saving"
    experiments:
      - name: gtsrb_quick_test
        dataset: gtsrb
        subset_size: 5  # Very small subset
        epochs: 1       # Just one epoch
        batch_size: 8   # Small batch size
        attack: pgd     # Single attack type

# Output configuration
output:
  base_dir: "results"
  consolidated_file: "all_results.csv"
  save_individual_results: true  # Whether to keep individual experiment CSV files

# Execution configuration
execution:
  parallel: true  # Whether to run experiments in parallel
  max_workers: 2  # Maximum number of parallel experiments
  gpu_ids: [0]   # List of GPU IDs to use
