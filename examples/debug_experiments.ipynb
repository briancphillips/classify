{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Experiments Configuration\n",
    "\n",
    "This notebook sets up debug experiments across multiple datasets (CIFAR-100, GTSRB, ImageNette) with various poisoning attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from config.experiment_config import create_config\n",
    "from utils.logging import setup_logging, get_logger\n",
    "\n",
    "# Initialize logging\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Configuration\n",
    "\n",
    "First, let's set up checkpoint handling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_checkpoint(model_type='wideresnet'):\n",
    "    \"\"\"Find the best or latest checkpoint for a model.\"\"\"\n",
    "    checkpoint_dir = Path('~/Notebooks/classify/checkpoints') / model_type\n",
    "    checkpoint_dir = checkpoint_dir.expanduser()\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        logger.warning(f\"Checkpoint directory {checkpoint_dir} does not exist\")\n",
    "        return None\n",
    "        \n",
    "    # First try to find best checkpoint\n",
    "    best_checkpoint = checkpoint_dir / 'wideresnet_best.pt'\n",
    "    if best_checkpoint.exists():\n",
    "        logger.info(f\"Found best checkpoint: {best_checkpoint}\")\n",
    "        return best_checkpoint\n",
    "        \n",
    "    # Otherwise get latest checkpoint\n",
    "    latest_checkpoint = checkpoint_dir / 'wideresnet_latest.pt'\n",
    "    if latest_checkpoint.exists():\n",
    "        logger.info(f\"Found latest checkpoint: {latest_checkpoint}\")\n",
    "        return latest_checkpoint\n",
    "        \n",
    "    logger.warning(f\"No checkpoints found in {checkpoint_dir}\")\n",
    "    return None\n",
    "\n",
    "checkpoint_path = find_checkpoint()\n",
    "if checkpoint_path:\n",
    "    logger.info(f\"Using checkpoint: {checkpoint_path}\")\n",
    "else:\n",
    "    logger.warning(\"No checkpoint found, will train from scratch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Configuration\n",
    "\n",
    "Let's check available hardware and set up device-specific configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Determine hardware configuration\n",
    "if torch.cuda.is_available():\n",
    "    device_info = f\"CUDA (GPU: {torch.cuda.get_device_name(0)})\"\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    gpu_ids = [0]\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_info = \"MPS (Apple Silicon)\"\n",
    "    gpu_ids = []\n",
    "else:\n",
    "    device_info = \"CPU\"\n",
    "    gpu_ids = []\n",
    "\n",
    "print(f\"Running on: {device_info}\")\n",
    "\n",
    "# Set hardware-dependent parameters\n",
    "num_workers = 4 if not torch.backends.mps.is_available() else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Base Configurations\n",
    "\n",
    "Now let's create configurations for each dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Common configuration for all datasets\n",
    "base_config = {\n",
    "    'model': {\n",
    "        'name': 'wrn-28-10',\n",
    "        'depth': 28,\n",
    "        'widen_factor': 10\n",
    "    },\n",
    "    'training': {\n",
    "        'batch_size': 128,\n",
    "        'num_workers': num_workers,\n",
    "        'pin_memory': True\n",
    "    },\n",
    "    'checkpoint': {\n",
    "        'save_dir': str(checkpoint_path.parent) if checkpoint_path else 'checkpoints',\n",
    "        'resume': True if checkpoint_path else False\n",
    "    },\n",
    "    'execution': {\n",
    "        'max_workers': 1,\n",
    "        'gpu_ids': gpu_ids\n",
    "    },\n",
    "    'output': {\n",
    "        'base_dir': 'results',\n",
    "        'save_models': True,\n",
    "        'save_frequency': 10,\n",
    "        'consolidated_file': 'debug_results.csv',\n",
    "        'save_individual_results': True\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create dataset-specific configurations\n",
    "cifar_config = create_config(\n",
    "    'cifar100',\n",
    "    **base_config,\n",
    "    training={'epochs': 200},\n",
    "    poison={\n",
    "        'poison_type': 'ga',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'ga_steps': 50,\n",
    "        'ga_iterations': 100,\n",
    "        'ga_lr': 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "gtsrb_config = create_config(\n",
    "    'gtsrb',\n",
    "    **base_config,\n",
    "    training={'epochs': 10},\n",
    "    poison={\n",
    "        'poison_type': 'pgd',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'pgd_eps': 0.3,\n",
    "        'pgd_alpha': 0.01,\n",
    "        'pgd_steps': 40\n",
    "    }\n",
    ")\n",
    "\n",
    "imagenette_config = create_config(\n",
    "    'imagenette',\n",
    "    **base_config,\n",
    "    training={\n",
    "        'epochs': 10,\n",
    "        'batch_size': 64  # Smaller batch size for ImageNette\n",
    "    },\n",
    "    poison={\n",
    "        'poison_type': 'pgd',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'pgd_eps': 0.3,\n",
    "        'pgd_alpha': 0.01,\n",
    "        'pgd_steps': 40\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Configurations created for all datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment Groups\n",
    "\n",
    "Now let's set up the experiment groups for comparing different attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "experiment_groups = {\n",
    "    'basic_comparison': {\n",
    "        'description': 'Basic comparison of attacks across different datasets',\n",
    "        'experiments': [\n",
    "            {\n",
    "                'name': 'cifar100_debug',\n",
    "                'dataset': 'cifar100',\n",
    "                'attacks': ['ga', 'label_flip']\n",
    "            },\n",
    "            {\n",
    "                'name': 'gtsrb_debug',\n",
    "                'dataset': 'gtsrb',\n",
    "                'attacks': ['pgd', 'ga', 'label_flip']\n",
    "            },\n",
    "            {\n",
    "                'name': 'imagenette_debug',\n",
    "                'dataset': 'imagenette',\n",
    "                'attacks': ['pgd', 'ga', 'label_flip']\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create final configuration with experiment groups\n",
    "final_config = create_config(\n",
    "    'cifar100',  # Base dataset\n",
    "    **base_config,\n",
    "    experiment_groups=experiment_groups\n",
    ")\n",
    "\n",
    "# Save the configuration\n",
    "config_path = 'experiments/debug_config.yaml'\n",
    "final_config.save_yaml(config_path)\n",
    "print(f\"Saved configuration to {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments\n",
    "\n",
    "Finally, let's run our experiments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "from run_experiments import ExperimentManager\n",
    "\n",
    "# Create and run experiment manager\n",
    "manager = ExperimentManager(config_path)\n",
    "print(f\"Total experiments to run: {manager.total_experiments}\")\n",
    "\n",
    "# Run experiments\n",
    "try:\n",
    "    manager.run_experiments()\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error during experiments: {str(e)}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
