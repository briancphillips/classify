{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Experiments Configuration\n",
    "\n",
    "This notebook sets up debug experiments across multiple datasets with their specific model architectures:\n",
    "- CIFAR-100: WideResNet (wrn-28-10)\n",
    "- GTSRB: Custom CNN\n",
    "- ImageNette: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import torch\n",
    "from pathlib import Path\n",
    "from config.experiment_config import create_config\n",
    "from utils.logging import setup_logging, get_logger\n",
    "\n",
    "# Initialize logging\n",
    "setup_logging()\n",
    "logger = get_logger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checkpoint Configuration\n",
    "\n",
    "Find checkpoints for each model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def find_checkpoint(model_type):\n",
    "    \"\"\"Find the best or latest checkpoint for a model.\"\"\"\n",
    "    checkpoint_dir = Path('~/Notebooks/classify/checkpoints') / model_type\n",
    "    checkpoint_dir = checkpoint_dir.expanduser()\n",
    "    \n",
    "    if not checkpoint_dir.exists():\n",
    "        logger.warning(f\"Checkpoint directory {checkpoint_dir} does not exist\")\n",
    "        return None\n",
    "        \n",
    "    # First try to find best checkpoint\n",
    "    best_checkpoint = checkpoint_dir / f'{model_type}_best.pt'\n",
    "    if best_checkpoint.exists():\n",
    "        logger.info(f\"Found best checkpoint: {best_checkpoint}\")\n",
    "        return best_checkpoint\n",
    "        \n",
    "    # Otherwise get latest checkpoint\n",
    "    latest_checkpoint = checkpoint_dir / f'{model_type}_latest.pt'\n",
    "    if latest_checkpoint.exists():\n",
    "        logger.info(f\"Found latest checkpoint: {latest_checkpoint}\")\n",
    "        return latest_checkpoint\n",
    "        \n",
    "    logger.warning(f\"No checkpoints found in {checkpoint_dir}\")\n",
    "    return None\n",
    "\n",
    "# Find checkpoints for each model type\n",
    "checkpoints = {\n",
    "    'cifar100': find_checkpoint('wideresnet'),\n",
    "    'gtsrb': find_checkpoint('custom-cnn'),\n",
    "    'imagenette': find_checkpoint('resnet50')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hardware Configuration\n",
    "\n",
    "Set up hardware-specific configurations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Determine hardware configuration\n",
    "if torch.cuda.is_available():\n",
    "    device_info = f\"CUDA (GPU: {torch.cuda.get_device_name(0)})\"\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "    gpu_ids = [0]\n",
    "elif torch.backends.mps.is_available():\n",
    "    device_info = \"MPS (Apple Silicon)\"\n",
    "    gpu_ids = []\n",
    "else:\n",
    "    device_info = \"CPU\"\n",
    "    gpu_ids = []\n",
    "\n",
    "print(f\"Running on: {device_info}\")\n",
    "\n",
    "# Set hardware-dependent parameters\n",
    "hardware_config = {\n",
    "    'execution': {\n",
    "        'max_workers': 1,\n",
    "        'gpu_ids': gpu_ids\n",
    "    },\n",
    "    'training': {\n",
    "        'num_workers': 4 if not torch.backends.mps.is_available() else 0,\n",
    "        'pin_memory': True\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Configurations\n",
    "\n",
    "Create configurations for each dataset with their specific model architectures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# CIFAR-100 with WideResNet\n",
    "cifar_config = create_config(\n",
    "    'cifar100',\n",
    "    **hardware_config,\n",
    "    training={'epochs': 200, 'batch_size': 128},\n",
    "    data={'subset_size': 50000},\n",
    "    checkpoint={\n",
    "        'save_dir': str(checkpoints['cifar100'].parent) if checkpoints['cifar100'] else 'checkpoints',\n",
    "        'resume': True if checkpoints['cifar100'] else False\n",
    "    },\n",
    "    poison={\n",
    "        'poison_type': 'ga',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'ga_steps': 50,\n",
    "        'ga_iterations': 100,\n",
    "        'ga_lr': 0.1\n",
    "    }\n",
    ")\n",
    "\n",
    "# GTSRB with Custom CNN\n",
    "gtsrb_config = create_config(\n",
    "    'gtsrb',\n",
    "    **hardware_config,\n",
    "    training={'epochs': 10, 'batch_size': 128},\n",
    "    data={'subset_size': 39209},\n",
    "    checkpoint={\n",
    "        'save_dir': str(checkpoints['gtsrb'].parent) if checkpoints['gtsrb'] else 'checkpoints',\n",
    "        'resume': True if checkpoints['gtsrb'] else False\n",
    "    },\n",
    "    poison={\n",
    "        'poison_type': 'pgd',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'pgd_eps': 0.3,\n",
    "        'pgd_alpha': 0.01,\n",
    "        'pgd_steps': 40\n",
    "    }\n",
    ")\n",
    "\n",
    "# ImageNette with ResNet50\n",
    "imagenette_config = create_config(\n",
    "    'imagenette',\n",
    "    **hardware_config,\n",
    "    training={'epochs': 10, 'batch_size': 64},\n",
    "    data={'subset_size': 9469},\n",
    "    checkpoint={\n",
    "        'save_dir': str(checkpoints['imagenette'].parent) if checkpoints['imagenette'] else 'checkpoints',\n",
    "        'resume': True if checkpoints['imagenette'] else False\n",
    "    },\n",
    "    poison={\n",
    "        'poison_type': 'pgd',\n",
    "        'poison_ratio': 0.1,\n",
    "        'batch_size': 32,\n",
    "        'pgd_eps': 0.3,\n",
    "        'pgd_alpha': 0.01,\n",
    "        'pgd_steps': 40\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Model architectures and dataset sizes:\")\n",
    "print(f\"CIFAR-100: {cifar_config.model} (size: {cifar_config.data.subset_size})\")\n",
    "print(f\"GTSRB: {gtsrb_config.model} (size: {gtsrb_config.data.subset_size})\")\n",
    "print(f\"ImageNette: {imagenette_config.model} (size: {imagenette_config.data.subset_size})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment Groups\n",
    "\n",
    "Set up experiment groups for comparing different attacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create experiment groups\n",
    "experiment_groups = {\n",
    "    'cifar100': {\n",
    "        'description': 'CIFAR-100 experiments with WideResNet',\n",
    "        'experiments': [cifar_config]\n",
    "    },\n",
    "    'gtsrb': {\n",
    "        'description': 'GTSRB experiments with Custom CNN',\n",
    "        'experiments': [gtsrb_config]\n",
    "    },\n",
    "    'imagenette': {\n",
    "        'description': 'ImageNette experiments with ResNet50',\n",
    "        'experiments': [imagenette_config]\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\nExperiment Groups:\")\n",
    "for name, group in experiment_groups.items():\n",
    "    print(f\"\\n{name}: {group['description']}\")\n",
    "    print(f\"Number of experiments: {len(group['experiments'])}\")\n",
    "    print(f\"Dataset size: {group['experiments'][0].data.subset_size}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
