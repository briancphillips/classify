{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-100 Training Notebook\n",
    "This notebook runs the CIFAR-100 training with detailed logging and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import yaml\n",
    "import logging\n",
    "\n",
    "from models import get_model, get_dataset\n",
    "from experiment.experiment import Trainer\n",
    "from utils.device import get_device\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load configuration\n",
    "with open('experiments/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# Get CIFAR-100 specific config\n",
    "cifar_config = {**config['defaults'], **config['dataset_defaults']['cifar100']}\n",
    "print(\"Training configuration:\")\n",
    "for k, v in cifar_config.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Setup device and model\n",
    "device = get_device()\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = get_model('cifar100').to(device)\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=cifar_config['label_smoothing'])\n",
    "\n",
    "# Setup optimizer\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=cifar_config['learning_rate'],\n",
    "    momentum=cifar_config['momentum'],\n",
    "    weight_decay=cifar_config['weight_decay']\n",
    ")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(model, criterion, optimizer, device, cifar_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get datasets and create dataloaders\n",
    "train_dataset = get_dataset('cifar100', train=True)\n",
    "test_dataset = get_dataset('cifar100', train=False)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=cifar_config['batch_size'],\n",
    "    shuffle=True,\n",
    "    num_workers=cifar_config['num_workers'],\n",
    "    pin_memory=cifar_config['pin_memory']\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=cifar_config['batch_size'],\n",
    "    shuffle=False,\n",
    "    num_workers=cifar_config['num_workers'],\n",
    "    pin_memory=cifar_config['pin_memory']\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training loop with progress bar\n",
    "num_epochs = 10  # Start with 10 epochs for testing\n",
    "train_losses = []\n",
    "train_accs = []\n",
    "test_losses = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs + 1), desc='Training Progress'):\n",
    "    # Train\n",
    "    trainer.train_epoch(train_loader, epoch)\n",
    "    train_loss = trainer.metrics['train_losses'][-1]\n",
    "    train_acc = trainer.metrics['train_accs'][-1]\n",
    "    train_losses.append(train_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    \n",
    "    # Evaluate\n",
    "    test_metrics = trainer.evaluate(test_loader, epoch)\n",
    "    test_losses.append(test_metrics['loss'])\n",
    "    test_accs.append(test_metrics['accuracy'])\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f\"\\nEpoch {epoch}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "    print(f\"Test Loss: {test_metrics['loss']:.4f} | Test Acc: {test_metrics['accuracy']:.2f}%\")\n",
    "    print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Early stopping check\n",
    "    if trainer.should_stop():\n",
    "        print(\"Early stopping triggered\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training curves\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Loss plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Accuracy plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_accs, label='Train Accuracy')\n",
    "plt.plot(test_accs, label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Test Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
